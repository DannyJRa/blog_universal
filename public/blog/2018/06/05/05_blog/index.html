<!DOCTYPE html>
<html lang="en-us">

  <head>
  <meta charset="utf-8">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>BigData with Spark</title>
  <meta name="author" content="" />

  
  <meta name="keywords" content="dannyjra, hugo, go">	
  

  
  <meta name="description" content="Uuuups">	
  

  <meta name="generator" content="Hugo 0.55.5" />

  <link href='//fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,500,700,800' rel='stylesheet' type='text/css'>

  
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

  
  <link href="../../../../../css/animate.css" rel="stylesheet">

  
  
    <link href="../../../../../css/style.blue.css" rel="stylesheet" id="theme-stylesheet">
  


  
  <link href="../../../../../css/custom.css" rel="stylesheet">

  
  
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
  <link rel="shortcut icon" href="../../../../../img/favicon.ico" type="image/x-icon" />
  <link rel="apple-touch-icon" href="../../../../../img/apple-touch-icon.png" />
  

  <link href="../../../../../css/owl.carousel.css" rel="stylesheet">
  <link href="../../../../../css/owl.theme.css" rel="stylesheet">

  <link rel="alternate" href="../../../../../index.xml" type="application/rss+xml" title="Universal">

  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@GoHugoIO">
  <meta name="twitter:title" content="BigData with Spark">
  <meta name="twitter:image" content="/img/banners/05_spark_ml_logo_BLOG.png">
  <meta name="twitter:description" content="Uuuups">

  
  <meta property="og:title" content="BigData with Spark" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="/blog/2018/06/05/05_blog//" />
  <meta property="og:image" content="img/logo_signature.svg" />

</head>


  <body>

    <div id="all">

        <header>

          <div class="navbar-affixed-top" data-spy="affix" data-offset-top="200">

    <div class="navbar navbar-default yamm" role="navigation" id="navbar">

        <div class="container">
            <div class="navbar-header">
                <a class="navbar-brand home" href="../../../../../">
                    <img src="../../../../../img/logo_signature.svg" alt="BigData with Spark logo" class="hidden-xs hidden-sm">
                    <img src="../../../../../img/logo_signature.svg" alt="BigData with Spark logo" class="visible-xs visible-sm">
                    <span class="sr-only">BigData with Spark - go to homepage</span>
                </a>
                <div class="navbar-buttons">
                    <button type="button" class="navbar-toggle btn-template-main" data-toggle="collapse" data-target="#navigation">
                      <span class="sr-only">Toggle Navigation</span>
                        <i class="fa fa-align-justify"></i>
                    </button>
                </div>
            </div>
            

            <div class="navbar-collapse collapse" id="navigation">
                <ul class="nav navbar-nav navbar-right">
                  
                  
                  
                  <li class="dropdown">
                    
                    <a href="../../../../../">Home</a>
                    
                  </li>
                  
                  
                  <li class="dropdown active">
                    
                    <a href="../../../../../blog/">Blog</a>
                    
                  </li>
                  
                  
                  <li class="dropdown">
                    
                    <a href="../../../../../projects/">Projects</a>
                    
                  </li>
                  
                  
                  <li class="dropdown">
                    
                    <a href="../../../../../contact/">Contact</a>
                    
                  </li>
                  
                </ul>
            </div>
            

            <div class="collapse clearfix" id="search">

                <form class="navbar-form" role="search">
                    <div class="input-group">
                        <input type="text" class="form-control" placeholder="Search">
                        <span class="input-group-btn">

                    <button type="submit" class="btn btn-template-main"><i class="fa fa-search"></i></button>

                </span>
                    </div>
                </form>

            </div>
            

        </div>
    </div>
    

</div>




        </header>

        <div id="heading-breadcrumbs">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h1>BigData with Spark</h1>
            </div>
        </div>
    </div>
</div>


        <div id="content">
            <div class="container">

                <div class="row">

                    

                    <div class="col-md-9" id="blog-post">

                        <p class="text-muted text-uppercase mb-small text-right">By <a href="#">DannyJRa</a> | June 5, 2018</p>

                        <div id="post-content">
                          <p>Original post here: <a href="https://dannyjra.github.io/05_Blog_BigData_Spark/01_blog_caret_Tut.html">https://dannyjra.github.io/05_Blog_BigData_Spark/01_blog_caret_Tut.html</a></p>

<p>Add summary desdcription of blog</p>

<h1 id="use-case">Use Case</h1>

<p>In this case a Ubuntu DSVM is deployed. The
virtual machine is created within its own resource group so that all
created resources (the VM, networking, disk, etc) can be deleted
easily. Code is also included, and run, to then delete the
resource group if the resource group was created within this
vignette. Once deleted consumption (cost) will cease.</p>

<h1 id="setup">Setup</h1>

<p>To get started we need to load our Azure credentials as well as the
user&rsquo;s ssh public key. Public keys on Linux are typically created on
the users desktop/laptop machine and will be found within
~/.ssh/id_rsa.pub. It will be convenient to create a credentials file
to contain this information.</p>

<p>#Authorization</p>

<p>We can simply source the credentials file in R.</p>

<pre><code class="language-r"># Load the required subscription resources: TID, CID, and KEY.
# Also includes the ssh PUBKEY for the user.

USER &lt;- Sys.info()[['user']]
#or set manually
USER&lt;-&quot;insider&quot;

source(&quot;~/02_CloudComputing/10_Secrets/Azure_Authentication_datascience_AWS.R&quot;)
</code></pre>

<p>If the required pacakges are not yet installed the following will do
so. You may need to install them into your own local library rather
than the system library if you are not a system user.</p>

<p>We can then load the required pacakges from the libraries.</p>

<h1 id="set-hdinsight">Set HDInsight</h1>

<h2 id="overview">Overview</h2>

<p><code>AzureSMR</code> provides an interface to manage resources on Microsoft Azure. The main functions address the following Azure Services:</p>

<ul>
<li>Azure Blob: List, Read and Write to Blob Services</li>
<li>Azure Resources: List, Create and Delete Azure Resource</li>
<li>Azure VM: List, Start and Stop Azure VMs</li>
<li>Azure HDI: List and Scale Azure HDInsight Clusters</li>
<li>Azure Hive: Run Hive queries against a HDInsight Cluster</li>
<li>Azure Spark: List and create Spark jobs/Sessions against a HDInsight Cluster(Livy) - EXPERIMENTAL</li>
<li>Azure Data Lake Store: ListStatus, GetFileStatus, MkDirs, Create (file), Append (file), Read (file), Delete</li>
</ul>

<p>For a detailed list of <code>AzureSMR</code> functions and their syntax please refer to the Help pages.</p>

<h2 id="configuring-authorisation-in-azure-active-directory">Configuring authorisation in Azure Active Directory</h2>

<p>To get started, please refer to the <a href="http://htmlpreview.github.io/?https://github.com/Microsoft/AzureSMR/blob/master/inst/doc/Authentication.html">authorisation tutorial</a></p>

<h2 id="load-the-package">Load the package</h2>

<pre><code class="language-r">library(AzureSMR)
</code></pre>

<h2 id="authenticating-against-the-azure-service">Authenticating against the Azure service</h2>

<p>The Azure APIs require many parameters to be managed. Rather than supplying all the arguments to every function call, <code>AzureSMR</code> uses an <code>azureActiveContext</code> object that caches arguments so you don&rsquo;t have to supply .</p>

<p>To create an <code>azureActiveContext</code> object and attempt to authenticate against the Azure service, use:</p>

<pre><code class="language-r">context &lt;- createAzureContext(tenantID=TID, clientID=CID, authKey=KEY)
</code></pre>

<p>##Create a resource group</p>

<pre><code class="language-r">azureCreateResourceGroup(context, resourceGroup = &quot;R_Control&quot;, location = &quot;centralus&quot;)
</code></pre>

<h2 id="manage-hdinsight-clusters">Manage HDInsight clusters</h2>

<p>You can use <code>AzureSMR</code> to manage <a href="https://azure.microsoft.com/en-gb/services/hdinsight/">HDInsight</a> clusters. To create a cluster use <code>azureCreateHDI()</code>.</p>

<p>For advanced configurations use Resource Templates (See below).
ca. 17 minutes</p>

<pre><code class="language-r">azureCreateHDI(context,
                 resourceGroup = &quot;R_control&quot;,
                 clustername = &quot;smrhdi&quot;, # only low case letters, digit, and dash.
                 storageAccount = &quot;testmystorage&quot;,
                 adminUser = &quot;hdiadmin&quot;,
                 adminPassword = &quot;AzureSMR_password123&quot;,
                 sshUser = &quot;hdisshuser&quot;,
                 sshPassword = &quot;AzureSMR_password123&quot;, 
                 kind = &quot;rserver&quot;,
               location=&quot;centralus&quot;)
</code></pre>

<p>Use <code>azureListHDI()</code> to list available clusters.</p>

<pre><code class="language-r">azureListHDI(context, resourceGroup =&quot;R_control&quot;)
</code></pre>

<p>Use <code>azureResizeHDI()</code> to resize a cluster
NOT_WORKING</p>

<pre><code class="language-r">azureResizeHDI(context, resourceGroup = &quot;R_control&quot;, clustername = &quot;smrhdi&quot;, role=&quot;workernode&quot;,size=3)

## azureResizeHDI: Request Submitted:  2016-06-23 18:50:57
## Resizing(R), Succeeded(S)
## RRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRR
## RRRRRRRRRRRRRRRRRRS
## Finished Resizing Sucessfully:  2016-06-23 19:04:43
## Finished:  2016-06-23 19:04:43
##                                                                                                                        ## Information 
## &quot; headnode ( 2 * Standard_D3_v2 ) workernode ( 5 * Standard_D3_v2 ) zookeepernode ( 3 * Medium ) edgenode0 ( 1 * Standard_D4_v2 )&quot; 
</code></pre>

<p>ADMIN TIP: If a deployment fails, go to the Azure Portal and look at <code>Activity logs</code> and look for failed deployments - this should explain why the deployment failed.</p>

<h2 id="hive-functions">Hive Functions</h2>

<p>You can use these functions to run and manage hive jobs on an HDInsight Cluster.</p>

<pre><code class="language-r">azureHiveStatus(context, clusterName = &quot;smrhdi&quot;, 
                hdiAdmin = &quot;hdiadmin&quot;, 
                hdiPassword = &quot;AzureSMR_password123&quot;)

azureHiveSQL(context, 
             CMD = &quot;select * from hivesampletable&quot;, 
             path = &quot;wasb://opendata@testmystorage1.blob.core.windows.net/&quot;)
</code></pre>

<h2 id="spark-functions-experimental">Spark functions (experimental)</h2>

<p><code>AzureSMR</code> provides some functions that allow HDInsight Spark aessions and jobs to be managed within an R Session.</p>

<p>To create a new Spark session (via <a href="https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server">Livy</a>) use <code>azureSparkNewSession()</code></p>

<pre><code class="language-r">azureSparkNewSession(context, clustername = &quot;spark1987&quot;, 
                     hdiAdmin = &quot;&quot;, 
                     hdiPassword = &quot;&quot;,
                     kind = &quot;pyspark&quot;)
</code></pre>

<p>To view the status of sessions use <code>azureSparkListSessions()</code>. Wait for status to be idle.</p>

<pre><code class="language-r">azureSparkListSessions(context, clustername = &quot;spark1987&quot;)
</code></pre>

<p>To send a command to the Spark Session use <code>azureSparkCMD()</code>. In this case it submits a Python routine. Ensure you preserve indents for Python.</p>

<pre><code class="language-r"># SAMPLE PYSPARK SCRIPT TO CALCULATE PI
pythonCmd &lt;- '
from pyspark import SparkContext
from operator import add
import sys
from random import random
partitions = 1
n = 20000000 * partitions
def f(_):
  x = random() * 2 - 1
  y = random() * 2 - 1
  return 1 if x ** 2 + y ** 2 &lt; 1 else 0
 
count = context.parallelize(range(1, n + 1), partitions).map(f).reduce(add)
Pi = (4.0 * count / n)
print(&quot;Pi is roughly %f&quot; % Pi)'                   
 
azureSparkCMD(context, CMD = pythonCmd, sessionID = &quot;0&quot;)

## [1] &quot;Pi is roughly 3.140285&quot;
</code></pre>

<p>Check Session variables are retained</p>

<pre><code class="language-r">azureSparkCMD(context, clustername = &quot;spark1987&quot;, CMD = &quot;print Pi&quot;, sessionID = &quot;0&quot;)

#[1] &quot;3.1422&quot;
</code></pre>

<p>You can also run SparkR sessions</p>

<p>NOT WORKING</p>

<pre><code class="language-r">azureSparkNewSession(context, clustername = &quot;spark1987&quot;, 
                     hdiAdmin = &quot;insider_danny&quot;, 
                     hdiPassword = &quot;.Alfonstini642856&quot;,
                     kind = &quot;sparkr&quot;)


azureSparkCMD(context, clustername = &quot;smrhdi&quot;, CMD = &quot;HW&lt;-'hello R'&quot;, sessionID = &quot;2&quot;)
azureSparkCMD(context, clustername = &quot;smrhdi&quot;, CMD = &quot;cat(HW)&quot;, sessionID = &quot;2&quot;)
</code></pre>

<h1 id="spark">Spark</h1>

<h3 id="chapter-9">&mdash; Chapter 9 &mdash;</h3>

<h3 id="big-data-machine-learning-with-r">&mdash; Big Data machine learning with R &mdash;</h3>

<h3 id="part-1">&mdash; Part 1 &mdash;</h3>

<h3 id="glm-logistic-regression-on-spark">&mdash; GLM - logistic regression on Spark &mdash;</h3>

<p>Sys.getenv(&ldquo;SPARK_HOME&rdquo;)</p>

<p>Sys.setenv(SPARK_HOME = &ldquo;/usr/hdp/2.4.2.0-258/spark&rdquo;)
Sys.getenv(&ldquo;SPARK_HOME&rdquo;)
Sys.setenv(&lsquo;SPARKR_SUBMIT_ARGS&rsquo;=&lsquo;&ldquo;&ndash;packages&rdquo; &ldquo;com.databricks:spark-csv_2.11:1.4.0&rdquo; &ldquo;sparkr-shell&rdquo;&lsquo;)
Sys.getenv(&ldquo;SPARKR_SUBMIT_ARGS&rdquo;)</p>

<p>library(rJava)
library(SparkR, lib.loc = c(file.path(Sys.getenv(&ldquo;SPARK_HOME&rdquo;), &ldquo;R&rdquo;, &ldquo;lib&rdquo;)))</p>

<p>sc &lt;- sparkR.init(master=&ldquo;yarn-client&rdquo;,
                  appName=&ldquo;SparkRStudio&rdquo;,
                  sparkJars = c(&ldquo;/usr/hdp/2.4.2.0-258/hadoop/hadoop-nfs.jar&rdquo;,
                                &ldquo;/usr/hdp/2.4.2.0-258/hadoop/hadoop-azure.jar&rdquo;,
                                &ldquo;/usr/hdp/2.4.2.0-258/hadoop/lib/azure-storage-2.2.0.jar&rdquo;),
                  sparkPackages=&ldquo;com.databricks:spark-csv_2.11:1.4.0&rdquo;)</p>

<p>sqlContext &lt;- sparkRSQL.init(sc)</p>

<p>schema &lt;- structType(structField(&ldquo;DAY_OF_WEEK&rdquo;, &ldquo;string&rdquo;),
                     structField(&ldquo;DEP_TIME&rdquo;, &ldquo;integer&rdquo;),
                     structField(&ldquo;DEP_DELAY&rdquo;, &ldquo;integer&rdquo;),
                     structField(&ldquo;ARR_TIME&rdquo;, &ldquo;integer&rdquo;),
                     structField(&ldquo;ARR_DELAY&rdquo;, &ldquo;integer&rdquo;),
                     structField(&ldquo;CANCELLED&rdquo;, &ldquo;integer&rdquo;),
                     structField(&ldquo;DIVERTED&rdquo;, &ldquo;integer&rdquo;),
                     structField(&ldquo;AIR_TIME&rdquo;, &ldquo;integer&rdquo;),
                     structField(&ldquo;DISTANCE&rdquo;, &ldquo;integer&rdquo;))</p>

<p>flights &lt;- read.df(sqlContext,
                   path = &ldquo;/user/swalko/data/flights_2014.csv&rdquo;,
                   source = &ldquo;com.databricks.spark.csv&rdquo;,
                   header = &ldquo;true&rdquo;,
                   schema = schema, nullValue = &ldquo;NA&rdquo;)</p>

<p>head(flights)
str(flights)
count(flights)</p>

<p>flights &lt;- filter(flights, flights$CANCELLED == 0)
flights &lt;- filter(flights, flights$DIVERTED == 0)</p>

<p>flights &lt;- flights[, -6:-7]
str(flights)</p>

<p>dtypes(flights)</p>

<p>registerTempTable(flights, &ldquo;flights&rdquo;)
flights &lt;- sql(sqlContext, &ldquo;SELECT *, IF(ARR_DELAY &gt; 0, 1, 0)
               AS ARR_DEL from flights&rdquo;)</p>

<p>str(flights)
#We need to re-register the DataFrame as a SQL table to reflect the changes in the previous query.
registerTempTable(flights, &ldquo;flights&rdquo;)
flights &lt;- sql(sqlContext, &ldquo;SELECT *, CASE WHEN(DEP_TIME &gt;= 500 AND DEP_TIME &lt; 1200)
               THEN (&lsquo;morning&rsquo;) WHEN(DEP_TIME &gt;= 1200 AND DEP_TIME &lt; 1700)
               THEN (&lsquo;afternoon&rsquo;) WHEN(DEP_TIME &gt;= 1700 AND DEP_TIME &lt; 2100)
               THEN (&lsquo;evening&rsquo;) ELSE(&lsquo;night&rsquo;) END AS DEP_PART from flights&rdquo;)
str(flights)
registerTempTable(flights, &ldquo;flights&rdquo;)</p>

<p>logit1 &lt;- glm(ARR_DEL ~ AIR_TIME + DISTANCE + DAY_OF_WEEK + DEP_PART + DEP_DELAY,
              data = flights, family = &ldquo;binomial&rdquo;)</p>

<p>summary(logit1)</p>

<p>head(select(flights, mean(flights$AIR_TIME)))
head(select(flights, mean(flights$DISTANCE)))
head(select(flights, mean(flights$DEP_DELAY)))</p>

<p>test1 &lt;- createDataFrame(sqlContext,
                         data = data.frame(AIR_TIME = 111.37,
                                           DISTANCE = 802.54,
                                           DEP_DELAY = 10.57,
                                           DAY_OF_WEEK = factor(rep(c(&ldquo;1&rdquo;, &ldquo;2&rdquo;,
                                                                      &ldquo;3&rdquo;, &ldquo;4&rdquo;,
                                                                      &ldquo;5&rdquo;, &ldquo;6&rdquo;, &ldquo;7&rdquo;), each=4)),
                                           DEP_PART = factor(rep(c(&ldquo;morning&rdquo;, &ldquo;afternoon&rdquo;,
                                                                   &ldquo;evening&rdquo;, &ldquo;night&rdquo;), times=7))))
showDF(test1)</p>

<p>predicted &lt;- predict(logit1, test1)
showDF(predicted, numRows = 28, truncate = FALSE)</p>

<p>test2 &lt;- createDataFrame(sqlContext,
                         data = data.frame(AIR_TIME=450,
                                           DISTANCE=3400,
                                           DEP_DELAY = -10,
                                           DAY_OF_WEEK = &ldquo;1&rdquo;,
                                           DEP_PART = &ldquo;morning&rdquo;))</p>

<p>showDF(predict(logit1, test2), truncate = FALSE)</p>

<p>flightsPred &lt;- predict(logit1, flights)
prediction &lt;- select(flightsPred, &ldquo;ARR_DEL&rdquo;, &ldquo;prediction&rdquo;)
showDF(prediction, numRows = 200)</p>

<h1 id="overall-accuracy-rate">Overall accuracy rate:</h1>

<p>prediction$success &lt;- ifelse(prediction$ARR_DEL == prediction$prediction, 1, 0)
registerTempTable(prediction, &ldquo;prediction&rdquo;)
correct &lt;- sql(sqlContext, &ldquo;SELECT count(success) FROM prediction WHERE success = 1&rdquo;)
total &lt;- count(prediction)
accuracy &lt;- collect(correct) / total
accuracy #82.7% accuracy</p>

<h1 id="accuracy-of-predicting-delayed-flights">Accuracy of predicting delayed flights:</h1>

<p>prediction &lt;- select(flightsPred, &ldquo;ARR_DEL&rdquo;, &ldquo;prediction&rdquo;)
pred_del &lt;- filter(prediction, prediction$ARR_DEL==1)
registerTempTable(pred_del, &ldquo;pred_del&rdquo;)
showDF(pred_del, numRows = 200)</p>

<p>pred_cor &lt;- sql(sqlContext, &ldquo;SELECT count(prediction) FROM prediction WHERE prediction = 1&rdquo;)
total_delayed &lt;- count(pred_del)
acc_pred &lt;- collect(pred_cor) / total_delayed
acc_pred #80% of delayed flights have been correctly identified</p>

<h1 id="using-flights-jan-2015-csv-dataset-we-can-apply-the-model-on-a-new-test-data">Using flights_jan_2015.csv dataset we can apply the model on a new test data:</h1>

<p>jan15 &lt;- read.df(sqlContext,
                 path = &ldquo;/user/swalko/data/flights_jan_2015.csv&rdquo;,
                 source = &ldquo;com.databricks.spark.csv&rdquo;,
                 header = &ldquo;true&rdquo;,
                 schema = schema,
                 nullValue = &ldquo;NA&rdquo;)</p>

<p>str(jan15)
jan15 &lt;- filter(jan15, jan15$CANCELLED == 0)
jan15 &lt;- filter(jan15, jan15$DIVERTED == 0)
jan15 &lt;- jan15[, -6:-7]</p>

<p>registerTempTable(jan15, &ldquo;jan15&rdquo;)
jan15 &lt;- sql(sqlContext, &ldquo;SELECT *, IF(ARR_DELAY &gt; 0, 1, 0)
             AS ARR_DEL from jan15&rdquo;)</p>

<p>registerTempTable(jan15, &ldquo;jan15&rdquo;)
jan15 &lt;- sql(sqlContext, &ldquo;SELECT *, CASE WHEN(DEP_TIME &gt;= 500 AND DEP_TIME &lt; 1200)
             THEN (&lsquo;morning&rsquo;) WHEN(DEP_TIME &gt;= 1200 AND DEP_TIME &lt; 1700)
             THEN (&lsquo;afternoon&rsquo;) WHEN(DEP_TIME &gt;= 1700 AND DEP_TIME &lt; 2100)
             THEN (&lsquo;evening&rsquo;) ELSE(&lsquo;night&rsquo;) END AS DEP_PART from jan15&rdquo;)</p>

<p>jan15 &lt;- select(jan15, &ldquo;DAY_OF_WEEK&rdquo;, &ldquo;DEP_DELAY&rdquo;,
                &ldquo;AIR_TIME&rdquo;, &ldquo;DISTANCE&rdquo;, &ldquo;DEP_PART&rdquo;, &ldquo;ARR_DEL&rdquo;)
str(jan15)</p>

<p>janPred &lt;- predict(logit1, jan15)
jan_eval &lt;- select(janPred, &ldquo;ARR_DEL&rdquo;, &ldquo;prediction&rdquo;)
showDF(jan_eval, numRows = 200)</p>

<h1 id="overall-accuracy-rate-1">Overall accuracy rate:</h1>

<p>jan_eval$success &lt;- ifelse(jan_eval$ARR_DEL == jan_eval$prediction, 1, 0)
registerTempTable(jan_eval, &ldquo;jan_eval&rdquo;)
correct &lt;- sql(sqlContext, &ldquo;SELECT count(success) FROM jan_eval WHERE success = 1&rdquo;)
total &lt;- count(jan_eval)
accuracy &lt;- collect(correct) / total
accuracy #80.7% accuracy</p>

<h1 id="accuracy-of-predicting-delayed-flights-1">Accuracy of predicting delayed flights:</h1>

<p>jan_eval &lt;- select(janPred, &ldquo;ARR_DEL&rdquo;, &ldquo;prediction&rdquo;)
jan_del &lt;- filter(jan_eval, jan_eval$ARR_DEL==1)
registerTempTable(jan_del, &ldquo;jan_del&rdquo;)
showDF(jan_del, numRows = 200)</p>

<p>jan_cor &lt;- sql(sqlContext, &ldquo;SELECT count(prediction) FROM jan_del WHERE prediction = 1&rdquo;)
total_delayed &lt;- count(jan_del)
acc_pred &lt;- collect(jan_cor) / total_delayed
acc_pred #67.3% of delayed flights have been correctly identified</p>

<h3 id="end-of-part-1">&mdash; End of Part 1 &mdash;</h3>

<h3 id="part-2">&mdash; Part 2 &mdash; ###</h3>

<h3 id="h2o-ai-on-r-naive-bayes">&mdash; H2O.ai on R - Naive Bayes &mdash;</h3>

<p>library(h2o)
h2o &lt;- h2o.init(ip = &ldquo;10.2.0.10&rdquo;, port = 54321, startH2O = F)
h2o.clusterInfo()</p>

<p>path1 &lt;- &ldquo;/home/swalko/data/flights_2014.csv&rdquo;
flights14 &lt;- h2o.uploadFile(path = path1,
                            destination_frame = &ldquo;flights14&rdquo;,
                            parse = TRUE, header = TRUE,
                            sep = &ldquo;,&rdquo;)</p>

<p>h2o.ls()</p>

<p>summary(flights14)
str(flights14)</p>

<p>flights14 &lt;- flights14[flights14$CANCELLED==0 &amp; flights14$DIVERTED==0, ]
flights14 &lt;- flights14[, -6:-7]</p>

<p>h2o.nacnt(flights14) #no missing values</p>

<p>flights14$DAY_OF_WEEK &lt;- as.factor(flights14$DAY_OF_WEEK)</p>

<p>avg_del &lt;- function(x) { sum(x[,3])/nrow(x) }
avg.del &lt;- h2o.ddply(flights14, &ldquo;DAY_OF_WEEK&rdquo;, FUN = avg_del)
as.data.frame(avg.del)</p>

<p>flights14$DEP_PART &lt;- h2o.cut(flights14$DEP_TIME,
                              c(1, 459, 1159, 1659, 2059, 2400),
                              labels = c(&ldquo;night&rdquo;, &ldquo;morning&rdquo;,
                                         &ldquo;afternoon&rdquo;, &ldquo;evening&rdquo;,
                                         &ldquo;night&rdquo;))
h2o.table(flights14$DEP_PART)</p>

<p>flights14$DEP_TIME &lt;- flights14$ARR_TIME &lt;- NULL</p>

<p>flights14$ARR_DEL &lt;- as.factor(h2o.ifelse(flights14$ARR_DELAY &gt; 0, 1, 0))</p>

<p>flights14$ARR_DELAY &lt;- NULL
h2o.table(flights14$ARR_DEL)
prop.table(h2o.table(flights14$ARR_DEL)) #42% of delayed flights overall</p>

<p>summary(flights14$DEP_DELAY)
flights14$DEP_DELAY &lt;- h2o.cut(flights14$DEP_DELAY,
                               c(-112, -15, -1, 1, 16, 2402),
                               labels = c(&ldquo;very early&rdquo;,
                                          &ldquo;somewhat early&rdquo;,
                                          &ldquo;on time&rdquo;,
                                          &ldquo;somewhat delayed&rdquo;,
                                          &ldquo;very delayed&rdquo;))
h2o.table(flights14$DEP_DELAY)</p>

<p>h2o.quantile(flights14$DISTANCE, prob = seq(0, 1, length = 4))
#h2o.hist(flights14$DISTANCE)
summary(flights14$DISTANCE)
flights14$DISTANCE &lt;- h2o.cut(flights14$DISTANCE,
                              c(31, 1000, 2000, 4983),
                              labels = c(&ldquo;short&rdquo;, &ldquo;medium&rdquo;, &ldquo;long&rdquo;))
h2o.table(flights14$DISTANCE)</p>

<p>h2o.quantile(flights14$AIR_TIME, prob = seq(0, 1, length = 4))
#h2o.hist(flights14$AIR_TIME)
summary(flights14$AIR_TIME)
flights14$AIR_TIME &lt;- h2o.cut(flights14$AIR_TIME,
                              c(7, 150, 300, 706),
                              labels = c(&ldquo;short&rdquo;, &ldquo;medium&rdquo;, &ldquo;long&rdquo;))
h2o.table(flights14$AIR_TIME)
str(flights14)</p>

<p>model1 &lt;- h2o.naiveBayes(x = 1:5, y = 6, training_frame = flights14, laplace = 1)
model1</p>

<p>str(model1)
h2o.auc(model1)
h2o.performance(model1)</p>

<p>path2 &lt;- &ldquo;/home/swalko/data/flights_jan_2015.csv&rdquo;
flightsJan15 &lt;- h2o.uploadFile(path = path2,
                               destination_frame = &ldquo;flightsJan15&rdquo;,
                               parse = TRUE, header = TRUE,
                               sep = &ldquo;,&rdquo;)</p>

<p>flightsJan15 &lt;- flightsJan15[flightsJan15$CANCELLED==0 &amp; flightsJan15$DIVERTED==0, ]
flightsJan15 &lt;- flightsJan15[, -6:-7]</p>

<p>h2o.nacnt(flightsJan15)</p>

<p>flightsJan15$DAY_OF_WEEK &lt;- as.factor(flightsJan15$DAY_OF_WEEK)
flightsJan15$DEP_PART &lt;- h2o.cut(flightsJan15$DEP_TIME,
                                 c(1, 459, 1159, 1659, 2059, 2400),
                                 labels = c(&ldquo;night&rdquo;, &ldquo;morning&rdquo;,
                                            &ldquo;afternoon&rdquo;, &ldquo;evening&rdquo;,
                                            &ldquo;night&rdquo;))</p>

<p>flightsJan15$DEP_TIME &lt;- flightsJan15$ARR_TIME &lt;- NULL
flightsJan15$ARR_DEL &lt;- as.factor(h2o.ifelse(flightsJan15$ARR_DELAY &gt; 0, 1, 0))
flightsJan15$ARR_DELAY &lt;- NULL
h2o.table(flightsJan15$ARR_DEL)
prop.table(h2o.table(flightsJan15$ARR_DEL)) #40% of delayed flights</p>

<p>summary(flightsJan15$DEP_DELAY)
flightsJan15$DEP_DELAY &lt;- h2o.cut(flightsJan15$DEP_DELAY,
                                  c(-48, -15, -1, 1, 16, 1988),
                                  labels = c(&ldquo;very early&rdquo;,
                                             &ldquo;somewhat early&rdquo;,
                                             &ldquo;on time&rdquo;,
                                             &ldquo;somewhat delayed&rdquo;,
                                             &ldquo;very delayed&rdquo;))
h2o.table(flightsJan15$DEP_DELAY)</p>

<p>h2o.quantile(flightsJan15$DISTANCE, prob = seq(0, 1, length = 4))
#h2o.hist(flightsJan15$DISTANCE)
summary(flightsJan15$DISTANCE)
flightsJan15$DISTANCE &lt;- h2o.cut(flightsJan15$DISTANCE,
                                 c(31, 1000, 2000, 4983),
                                 labels = c(&ldquo;short&rdquo;,
                                            &ldquo;medium&rdquo;,
                                            &ldquo;long&rdquo;))
h2o.table(flightsJan15$DISTANCE)</p>

<p>h2o.quantile(flightsJan15$AIR_TIME, prob = seq(0, 1, length = 4))
#h2o.hist(flightsJan15$AIR_TIME)
summary(flightsJan15$AIR_TIME)
flightsJan15$AIR_TIME &lt;- h2o.cut(flightsJan15$AIR_TIME,
                                 c(8, 150, 300, 676),
                                 labels = c(&ldquo;short&rdquo;,
                                            &ldquo;medium&rdquo;,
                                            &ldquo;long&rdquo;))
h2o.table(flightsJan15$AIR_TIME)</p>

<p>str(flightsJan15)</p>

<p>fit1 &lt;- h2o.predict(object = model1, newdata = flightsJan15)
fit1</p>

<p>h2o.performance(model1, newdata = flightsJan15)</p>

<h3 id="end-of-part-2">&mdash; End of Part 2 &mdash;</h3>

<h3 id="part-3">&mdash; Part 3 &mdash;</h3>

<h3 id="neural-networks-and-deep-learning-on-h2o-ai">&mdash; Neural Networks and Deep Learning on H2O.ai &mdash;</h3>

<p>rm(list=ls())
path1 &lt;- &ldquo;/home/swalko/data/flights_2014.csv&rdquo;
flights14 &lt;- h2o.uploadFile(path = path1,
                            destination_frame = &ldquo;flights14&rdquo;,
                            parse = TRUE, header = TRUE,
                            sep = &ldquo;,&rdquo;)
h2o.ls()</p>

<p>#summary(flights14)
#str(flights14)</p>

<p>flights14 &lt;- flights14[flights14$CANCELLED==0 &amp; flights14$DIVERTED==0, ]
flights14 &lt;- flights14[, -6:-7]</p>

<p>flights14$DAY_OF_WEEK &lt;- as.factor(flights14$DAY_OF_WEEK)
flights14$ARR_DEL &lt;- as.factor(h2o.ifelse(flights14$ARR_DELAY &gt; 0, 1, 0))
flights14$ARR_DELAY &lt;- flights14$ARR_TIME &lt;- NULL
str(flights14)</p>

<p>path2 &lt;- &ldquo;/home/swalko/data/flights_jan_2015.csv&rdquo;
flightsJan15 &lt;- h2o.uploadFile(path = path2,
                               destination_frame = &ldquo;flightsJan15&rdquo;,
                               parse = TRUE, header = TRUE,
                               sep = &ldquo;,&rdquo;)</p>

<p>flightsJan15 &lt;- flightsJan15[flightsJan15$CANCELLED==0 &amp; flightsJan15$DIVERTED==0, ]
flightsJan15 &lt;- flightsJan15[, -6:-7]</p>

<p>flightsJan15$DAY_OF_WEEK &lt;- as.factor(flightsJan15$DAY_OF_WEEK)
flightsJan15$ARR_DEL &lt;- as.factor(h2o.ifelse(flightsJan15$ARR_DELAY &gt; 0, 1, 0))
flightsJan15$ARR_DELAY &lt;- flightsJan15$ARR_TIME &lt;- NULL
str(flightsJan15)</p>

<p>model2 &lt;- h2o.deeplearning(x = 1:5, y = 6, training_frame = flights14,
                           validation_frame = flightsJan15,
                           hidden = c(10, 5, 3),
                           epochs = 5)</p>

<p>summary(model2)</p>

<p>model3 &lt;- h2o.deeplearning(x = 1:5, y = 6, training_frame = flights14,
                           validation_frame = flightsJan15,
                           epochs = 2)</p>

<p>summary(model3)</p>

<p>h2o.shutdown()</p>

<h3 id="end-of-part-3">&mdash; End of Part 3 &mdash;</h3>

<h3 id="the-end-of-chapter-9">&mdash; The end of Chapter 9 &mdash;</h3>
                        </div>
                        
                        
                        <div id="comments">
                            <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "blog-dannyrasch" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
                        </div>
                        

                    </div>
                    

                    

                    

                    <div class="col-md-3">

                        

                        

<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
      <h3 class="panel-title">Search</h3>
    </div>

    <div class="panel-body">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" role="search">
            <div class="input-group">
                <input type="search" name="q" class="form-control" placeholder="Search">
                <input type="hidden" name="sitesearch" value="/">
                <span class="input-group-btn">
                    <button type="submit" class="btn btn-template-main"><i class="fa fa-search"></i></button>
                </span>
            </div>
        </form>
    </div>
</div>







<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
      <h3 class="panel-title">Categories</h3>
    </div>

    <div class="panel-body">
        <ul class="nav nav-pills nav-stacked">
            
            <li><a href="../../../../../categories/cloud">cloud (3)</a>
            </li>
            
            <li><a href="../../../../../categories/datascience">datascience (1)</a>
            </li>
            
            <li><a href="../../../../../categories/python">python (3)</a>
            </li>
            
            <li><a href="../../../../../categories/r">r (9)</a>
            </li>
            
        </ul>
    </div>
</div>








<div class="panel sidebar-menu">
    <div class="panel-heading">
      <h3 class="panel-title">Tags</h3>
    </div>

    <div class="panel-body">
        <ul class="tag-cloud">
            
            <li><a href="../../../../../tags/azure"><i class="fa fa-tags"></i> azure</a>
            </li>
            
            <li><a href="../../../../../tags/bigdata"><i class="fa fa-tags"></i> bigdata</a>
            </li>
            
            <li><a href="../../../../../tags/docker"><i class="fa fa-tags"></i> docker</a>
            </li>
            
            <li><a href="../../../../../tags/engineering"><i class="fa fa-tags"></i> engineering</a>
            </li>
            
            <li><a href="../../../../../tags/gcp"><i class="fa fa-tags"></i> gcp</a>
            </li>
            
            <li><a href="../../../../../tags/linux"><i class="fa fa-tags"></i> linux</a>
            </li>
            
            <li><a href="../../../../../tags/ml"><i class="fa fa-tags"></i> ml</a>
            </li>
            
            <li><a href="../../../../../tags/r-package"><i class="fa fa-tags"></i> r-package</a>
            </li>
            
            <li><a href="../../../../../tags/rstudio"><i class="fa fa-tags"></i> rstudio</a>
            </li>
            
            <li><a href="../../../../../tags/set-up"><i class="fa fa-tags"></i> set-up</a>
            </li>
            
            <li><a href="../../../../../tags/shiny"><i class="fa fa-tags"></i> shiny</a>
            </li>
            
            <li><a href="../../../../../tags/viz"><i class="fa fa-tags"></i> viz</a>
            </li>
            
            <li><a href="../../../../../tags/webdev"><i class="fa fa-tags"></i> webdev</a>
            </li>
            
        </ul>
    </div>
</div>






                        

                    </div>
                    

                    

                </div>
                

            </div>
            
        </div>
        

        <footer id="footer">
    <div class="container">

        
        <div class="col-md-4 col-sm-6">
            <h4>About us</h4>

            dannyrasch.com was created and is maintained by me, Danny J. Rasch.

            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

        <div class="col-md-4 col-sm-6">

             
            <h4>Recent posts</h4>

            <div class="blog-entries">
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="../../../../../blog/2019/05/09/72_nginx_blog/">
                          
                            <img src="../../../../../img/banners/72_Nginx_BLOG.png" class="img-responsive" alt="Installing Nginx Server">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="../../../../../blog/2019/05/09/72_nginx_blog/">Installing Nginx Server</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="../../../../../blog/2019/04/27/70_vscode_blog/">
                          
                            <img src="../../../../../img/banners/70_vscode-ide.jpg" class="img-responsive" alt="VS-Code as a Server">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="../../../../../blog/2019/04/27/70_vscode_blog/">VS-Code as a Server</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="../../../../../blog/2019/04/14/63_cloud_scheduler_blog/">
                          
                            <img src="../../../../../img/banners/63_GoogleCloudFunctions_Title.png" class="img-responsive" alt="GCP - Cloud Scheduler">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="../../../../../blog/2019/04/14/63_cloud_scheduler_blog/">GCP - Cloud Scheduler</a></h5>
                    </div>
                </div>
                
            </div>

            <hr class="hidden-md hidden-lg">
             

        </div>
        

        
        <div class="col-md-4 col-sm-6">

          <h4>Contact</h4>

            <strong>Universal Ltd.</strong>
        <br>Sihlquai 131
        #<br>Newtown upon River
        #<br>45Y 73J
        <br>Zurich
        <br>
        <strong>Switzerland</strong>

            <a href="../../../../../contact" class="btn btn-small btn-template-main">Go to contact page</a>

            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

    </div>
    
</footer>







<div id="copyright">
    <div class="container">
        <div class="col-md-12">
            
            <p class="pull-left">Copyright (c) 2019, DannyJRa</p>
            
            <p class="pull-right">
              Template by <a href="http://bootstrapious.com/free-templates">Bootstrapious</a>.
              

              Ported to Hugo by <a href="https://github.com/devcows/hugo-universal-theme">DevCows</a>
            </p>
        </div>
    </div>
</div>





    </div>
    

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-140052731-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

<script src="//code.jquery.com/jquery-3.1.1.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/waypoints/4.0.1/jquery.waypoints.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/Counter-Up/1.0/jquery.counterup.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-parallax/1.1.3/jquery-parallax.js"></script>

<script src="//maps.googleapis.com/maps/api/js?key=AIzaSyAUNgKCDBYRR7Zos2_N1o0aQkwW3nvo9s8&v=3.exp"></script>

<script src="../../../../../js/hpneo.gmaps.js"></script>
<script src="../../../../../js/gmaps.init.js"></script>
<script src="../../../../../js/front.js"></script>


<script src="../../../../../js/owl.carousel.min.js"></script>


  </body>
</html>
